{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoNRw9XHCtagG+NOIFBr1E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharvadesai1/ChatApp/blob/main/lungs_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjDAF3n17uQu"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive/\""
      ],
      "metadata": {
        "id": "PsPT2LUE8LyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_path = \"/content/drive/My Drive/Lung_Disease_Dataset.zip\"\n",
        "extract_path = \"/content/Lung_Disease_Dataset\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction Complete!\")"
      ],
      "metadata": {
        "id": "F47zS0AN8Oav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, GlobalMaxPooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB3\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "wLXeUDyr72qC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/Lung_Disease_Dataset/train'\n",
        "valid_path = '/content/Lung_Disease_Dataset/val'\n",
        "test_path = '/content/Lung_Disease_Dataset/test'"
      ],
      "metadata": {
        "id": "vdBRJ9h88c8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class labels\n",
        "class_labels = ['Bacterial Pneumonia', 'Corona Virus Disease', 'Normal', 'Tuberculosis', 'Viral Pneumonia']"
      ],
      "metadata": {
        "id": "H2eXKXS98eDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image preprocessing & augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")"
      ],
      "metadata": {
        "id": "3DIlA0hx8iYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and validation datasets\n",
        "train_gen = datagen.flow_from_directory(\n",
        "    train_path, target_size=(380, 380), batch_size=32, class_mode='categorical')\n",
        "\n",
        "valid_gen = datagen.flow_from_directory(\n",
        "    valid_path, target_size=(380, 380), batch_size=32, class_mode='categorical')"
      ],
      "metadata": {
        "id": "cfpFMUzV8qdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EfficientNet with pre-trained weights and remove top layers\n",
        "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(380, 380, 3))\n",
        "base_model.trainable = False  # Freeze base model"
      ],
      "metadata": {
        "id": "A1XVSAmu8rjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "my_model = Sequential([\n",
        "    Input(shape=(380, 380, 3)),\n",
        "    base_model,\n",
        "    GlobalMaxPooling2D(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(5, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "Ln6AUvgq8vPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "my_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dQI5fAwQ8ylo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "epochs = 10  # Adjust based on available resources\n",
        "history = my_model.fit(train_gen, validation_data=valid_gen, epochs=epochs)"
      ],
      "metadata": {
        "id": "Kz9-kQ2m82uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "my_model.save(\"lungs_model.h5\")\n",
        "print(\"Model saved as lungs_model.h5\")"
      ],
      "metadata": {
        "id": "2sE5u2ew85V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training history\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss')\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)"
      ],
      "metadata": {
        "id": "PEQuX_CS884e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict an image\n",
        "def predict_image(image_path, model, class_labels):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (380, 380))\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    prediction = model.predict(img)\n",
        "    class_idx = np.argmax(prediction)\n",
        "    class_name = class_labels[class_idx]\n",
        "    confidence = prediction[0][class_idx]\n",
        "\n",
        "    plt.imshow(cv2.imread(image_path))\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Predicted: {class_name} ({confidence:.2f})')\n",
        "    plt.show()\n",
        "\n",
        "    return class_name"
      ],
      "metadata": {
        "id": "QsvPWt4Z9DY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage: Upload an image and predict\n",
        "def upload_and_predict():\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    for img_path in uploaded.keys():\n",
        "        print(f\"Processing: {img_path}\")\n",
        "        prediction = predict_image(img_path, my_model, class_labels)\n",
        "        print(f\"Predicted Disease: {prediction}\")\n",
        "\n",
        "upload_and_predict()"
      ],
      "metadata": {
        "id": "49N6MFqU9EeJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}